using Pkg
Pkg.activate("leiden")

using CSV, DataFrames, #Tensors, CategoricalArrays, 
    #SparseArrays, Distances,
    Flux, ProgressMeter, CUDA
include("fns.jl")

epochs=100
batchsize=1024
Î· = 0.01
Î» = 0

frac = 10
b = 32
bfÅ‹ = 1:32
ğ¤ = 1:128
ğ›„ = rand(Uniform(0.1,3),128);
ğ = 128

dat = (DataFrame âˆ˜ CSV.File)("z_dat.csv",normalizenames=true);
dat = (scaledat âˆ˜ Matrix)(dat[:,2:end]);
dat = hcat(filter(x->sum(x) != 0,eachslice(dat,dims=2))...);

n,m = size(dat)
n_Y = Integer(2^round(log2(n) - log2(frac)))
n_X = n - n_Y

tmp = map(_->sampledat(dat',n_Y),1:b);

test = mapreduce(x->x[1],zcat,tmp);
train = mapreduce(x->x[2],zcat,tmp);

X = permutedims(train,(3,1,2)) |> gpu;
Y = permutedims(test,(3,1,2)) |> gpu;

ğš¯_e = map(1:b) do _
    mapreduce(Å‹->Dense(m => Å‹,relu),
              (x...)->Parallel(x...,vcat),
              bfÅ‹)
end |> gpu;

ğš¯_d = map(1:b) do _
    mapreduce(Å‹->Dense(Å‹ => m,relu),
              (x...)->Parallel(x...,vcat),
              bfÅ‹)
end |> gpu;
    
loader = map(eachslice(X,dims=1)) do X_b
    Flux.DataLoader((X_b,repeat(X_b,outer=(length(bfÅ‹),1))),
                    batchsize=batchsize, shuffle=true)
end |>gpu;

opt = Flux.Optimiser(Flux.AdamW(Î·), Flux.WeightDecay(Î»))

@showprogress map(1:epochs) do _
    map(ğš¯_e,ğš¯_d,loader) do Î˜_e,Î˜_d,l
        function loss(X,Y)
            YÌ‚ = (Î˜_d âˆ˜ Î˜_e)(X)
            L = Flux.mse(YÌ‚,Y)
            return L
        end
        Flux.train!(loss,Flux.params(Î˜_e,Î˜_d),l,opt)
    end
end

        
            
